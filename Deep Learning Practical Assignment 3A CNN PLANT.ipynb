{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d64183c",
   "metadata": {},
   "source": [
    "Use any dataset of plant disease and design a plant disease detection system using CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f8845e",
   "metadata": {},
   "source": [
    "Importing Images & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68a78014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab0a98fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/datasets/noulam/tomato (Link to the dataset)\n",
    "\n",
    "#Originally New Plant Diseases Dataset(Augmented) contains two folders [train & valid] each containing 10 directories i.e. 10 classes - 1. Tomato___Bacterial_spot 2. Tomato___Early_blight 3. Tomato___Late_blight 4. Tomato___Leaf_Mold 5. Tomato___Septoria_leaf_spot 6. Tomato___Spider_mites Two-spotted_spider_mite 7. Tomato___Target_Spot 8. Tomato___Tomato_Yellow_Leaf_Curl_Virus 9. Tomato___Tomato_mosaic_virus 10. Tomato___healthy [Train - 18345 Total Images, Valid - 4585 Total Images]  \n",
    "\n",
    "#But for training & validating we have taken only three classes namely 1. Tomato___Bacterial_spot 2. Tomato___Early_blight 3. Tomato___healthy each class containing 200 images i.e. total images - 600 [Train - 600 Total Images, Valid - 600 Total Images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccdfd166",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to the New Plant Diseases Dataset(Augmented)\n",
    "train_dir = r'D:\\DL Practical\\New Plant Diseases Dataset(Augmented)\\train'\n",
    "val_dir = r'D:\\DL Practical\\New Plant Diseases Dataset(Augmented)\\valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "871343bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ece912",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d22e8b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(img_size, img_size),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38828670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_generator = val_datagen.flow_from_directory(val_dir,\n",
    "                                                target_size=(img_size, img_size),\n",
    "                                                batch_size=batch_size,\n",
    "                                                class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf620258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___healthy']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fddeb0",
   "metadata": {},
   "source": [
    "Building our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c206b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdb610c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 222, 222, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 109, 109, 64)     256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 52, 52, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18432)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               2359424   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,499,203\n",
      "Trainable params: 2,498,627\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add((Conv2D(32, (3,3), activation='relu', input_shape=(img_size, img_size, 3))))\n",
    "model.add(BatchNormalization()) \n",
    "model.add((MaxPooling2D(2,2)))\n",
    "model.add((Conv2D(64, (3,3), activation='relu')))\n",
    "model.add(BatchNormalization()) \n",
    "model.add((MaxPooling2D(2,2)))\n",
    "model.add((Conv2D(64, (3,3), activation='relu')))\n",
    "model.add(BatchNormalization()) \n",
    "model.add((MaxPooling2D(2,2)))\n",
    "model.add((Conv2D(128, (3,3), activation='relu')))\n",
    "model.add(BatchNormalization()) \n",
    "model.add((MaxPooling2D(2,2)))\n",
    "\n",
    "model.add((Flatten()))\n",
    "\n",
    "model.add((Dense(128, activation='relu')))\n",
    "model.add((Dropout(0.2)))\n",
    "model.add((Dense(64, activation='relu')))\n",
    "model.add((Dense(train_generator.num_classes, activation='softmax')))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "502596da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fe6c7e",
   "metadata": {},
   "source": [
    "Training our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5122228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "19/19 [==============================] - 154s 7s/step - loss: 1.4757 - accuracy: 0.7417 - val_loss: 2.6157 - val_accuracy: 0.3817\n",
      "Epoch 2/30\n",
      "19/19 [==============================] - 156s 8s/step - loss: 0.3824 - accuracy: 0.8950 - val_loss: 3.8763 - val_accuracy: 0.3533\n",
      "Epoch 3/30\n",
      "19/19 [==============================] - 166s 9s/step - loss: 0.2046 - accuracy: 0.9450 - val_loss: 3.9757 - val_accuracy: 0.5700\n",
      "Epoch 4/30\n",
      "19/19 [==============================] - 92s 5s/step - loss: 0.3855 - accuracy: 0.9200 - val_loss: 4.8410 - val_accuracy: 0.3333\n",
      "Epoch 5/30\n",
      "19/19 [==============================] - 75s 4s/step - loss: 0.2907 - accuracy: 0.9217 - val_loss: 3.1909 - val_accuracy: 0.5667\n",
      "Epoch 6/30\n",
      "19/19 [==============================] - 86s 5s/step - loss: 0.1792 - accuracy: 0.9517 - val_loss: 6.2633 - val_accuracy: 0.3867\n",
      "Epoch 7/30\n",
      "19/19 [==============================] - 77s 4s/step - loss: 0.1001 - accuracy: 0.9700 - val_loss: 7.9489 - val_accuracy: 0.3417\n",
      "Epoch 8/30\n",
      "19/19 [==============================] - 75s 4s/step - loss: 0.0805 - accuracy: 0.9783 - val_loss: 10.2267 - val_accuracy: 0.3333\n",
      "Epoch 9/30\n",
      "19/19 [==============================] - 75s 4s/step - loss: 0.2174 - accuracy: 0.9617 - val_loss: 8.7054 - val_accuracy: 0.2867\n",
      "Epoch 10/30\n",
      "19/19 [==============================] - 78s 4s/step - loss: 0.1027 - accuracy: 0.9633 - val_loss: 9.5749 - val_accuracy: 0.3367\n",
      "Epoch 11/30\n",
      "19/19 [==============================] - 80s 4s/step - loss: 0.1115 - accuracy: 0.9683 - val_loss: 12.7514 - val_accuracy: 0.3333\n",
      "Epoch 12/30\n",
      "19/19 [==============================] - 77s 4s/step - loss: 0.0695 - accuracy: 0.9767 - val_loss: 15.5847 - val_accuracy: 0.3333\n",
      "Epoch 13/30\n",
      "19/19 [==============================] - 79s 4s/step - loss: 0.1248 - accuracy: 0.9750 - val_loss: 8.3314 - val_accuracy: 0.4567\n",
      "Epoch 14/30\n",
      "19/19 [==============================] - 81s 4s/step - loss: 0.2641 - accuracy: 0.9500 - val_loss: 5.6487 - val_accuracy: 0.4617\n",
      "Epoch 15/30\n",
      "19/19 [==============================] - 75s 4s/step - loss: 0.4349 - accuracy: 0.9333 - val_loss: 9.1991 - val_accuracy: 0.3550\n",
      "Epoch 16/30\n",
      "19/19 [==============================] - 74s 4s/step - loss: 0.1672 - accuracy: 0.9617 - val_loss: 2.7760 - val_accuracy: 0.5633\n",
      "Epoch 17/30\n",
      "19/19 [==============================] - 74s 4s/step - loss: 0.0916 - accuracy: 0.9767 - val_loss: 3.9636 - val_accuracy: 0.6367\n",
      "Epoch 18/30\n",
      "19/19 [==============================] - 74s 4s/step - loss: 0.1261 - accuracy: 0.9633 - val_loss: 12.5124 - val_accuracy: 0.3900\n",
      "Epoch 19/30\n",
      "19/19 [==============================] - 74s 4s/step - loss: 0.1439 - accuracy: 0.9750 - val_loss: 15.2509 - val_accuracy: 0.3467\n",
      "Epoch 20/30\n",
      "19/19 [==============================] - 73s 4s/step - loss: 0.0928 - accuracy: 0.9783 - val_loss: 2.8503 - val_accuracy: 0.7350\n",
      "Epoch 21/30\n",
      "19/19 [==============================] - 79s 4s/step - loss: 0.1526 - accuracy: 0.9683 - val_loss: 1.7919 - val_accuracy: 0.7300\n",
      "Epoch 22/30\n",
      "19/19 [==============================] - 85s 5s/step - loss: 0.1998 - accuracy: 0.9650 - val_loss: 6.1096 - val_accuracy: 0.6233\n",
      "Epoch 23/30\n",
      "19/19 [==============================] - 74s 4s/step - loss: 0.1421 - accuracy: 0.9667 - val_loss: 6.6821 - val_accuracy: 0.5600\n",
      "Epoch 24/30\n",
      "19/19 [==============================] - 74s 4s/step - loss: 0.1320 - accuracy: 0.9683 - val_loss: 2.8923 - val_accuracy: 0.6950\n",
      "Epoch 25/30\n",
      "19/19 [==============================] - 78s 4s/step - loss: 0.0463 - accuracy: 0.9883 - val_loss: 3.2431 - val_accuracy: 0.6567\n",
      "Epoch 26/30\n",
      "19/19 [==============================] - 75s 4s/step - loss: 0.0274 - accuracy: 0.9917 - val_loss: 14.1886 - val_accuracy: 0.4283\n",
      "Epoch 27/30\n",
      "19/19 [==============================] - 75s 4s/step - loss: 0.1706 - accuracy: 0.9783 - val_loss: 3.9287 - val_accuracy: 0.8417\n",
      "Epoch 28/30\n",
      "19/19 [==============================] - 75s 4s/step - loss: 0.1910 - accuracy: 0.9717 - val_loss: 2.7364 - val_accuracy: 0.7583\n",
      "Epoch 29/30\n",
      "19/19 [==============================] - 76s 4s/step - loss: 0.1298 - accuracy: 0.9750 - val_loss: 2.5816 - val_accuracy: 0.7950\n",
      "Epoch 30/30\n",
      "19/19 [==============================] - 75s 4s/step - loss: 0.1154 - accuracy: 0.9783 - val_loss: 5.2757 - val_accuracy: 0.7300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x259222bb8e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, epochs=30, validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310a3486",
   "metadata": {},
   "source": [
    "Evaluating our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d0c7b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 17s 882ms/step - loss: 5.2757 - accuracy: 0.7300\n",
      "Loss : 5.275655269622803\n",
      "Accuracy (Test Data) : 73.00000190734863\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(val_generator)\n",
    "print(\"Loss :\",loss)\n",
    "print(\"Accuracy (Test Data) :\",accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e54a4d4",
   "metadata": {},
   "source": [
    "Testing our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "def8412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "img_path =r'D:\\DL Practical\\New Plant Diseases Dataset(Augmented)\\valid\\Tomato___Early_blight\\28d03063-a772-4136-80fd-3bbff0fffa41___RS_Erly.B 7370.JPG'\n",
    "img = load_img(img_path, target_size=(224, 224))\n",
    "img_array = img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf0c1fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 328ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(img_array)\n",
    "class_names=['Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___healthy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5965336f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.0037482e-03 9.9099624e-01 2.4914294e-16]]\n",
      "1\n",
      "Predicted class: Tomato___Early_blight\n"
     ]
    }
   ],
   "source": [
    "predicted_class = np.argmax(prediction)\n",
    "print(prediction)\n",
    "print(predicted_class)\n",
    "print('Predicted class:', class_names[predicted_class])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
